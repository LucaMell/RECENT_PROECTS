{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7lAXMiUksh0U"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7w6ZP7UhyxU"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import joblib\n",
    "import cv2\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import skimage.io\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "#import pytesseract\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from random import shuffle\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,precision_score,recall_score\n",
    "from statistics import mode\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,precision_score,recall_score\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import h5py\n",
    "from keras import models   \n",
    "from sklearn.metrics import classification_report\n",
    "from random import randint\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "iJjuBpFLjlU_",
    "outputId": "2b2c1dfd-9440-4ad1-d956-6b647ca13f80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E:/BGB_example_files_test_last/images/Purchase_Order/PKM_C454e19051314380-1.png 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:/BGB_example_files_test_last/images/Internal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:/BGB_example_files_test_last/images/Labels/P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:/BGB_example_files_test_last/images/OCB/PKM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:/BGB_example_files_test_last/images/OCB/PKM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:/BGB_example_files_test_last/images/Delivery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E:/BGB_example_files_test_last/images/Internal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E:/BGB_example_files_test_last/images/Rental_A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E:/BGB_example_files_test_last/images/OCB/PKM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E:/BGB_example_files_test_last/images/OCB/PKM_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E:/BGB_example_files_test_last/images/Refunds/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  E:/BGB_example_files_test_last/images/Purchase_Order/PKM_C454e19051314380-1.png 18\n",
       "0  E:/BGB_example_files_test_last/images/Internal...                                \n",
       "1  E:/BGB_example_files_test_last/images/Labels/P...                                \n",
       "2  E:/BGB_example_files_test_last/images/OCB/PKM_...                                \n",
       "3  E:/BGB_example_files_test_last/images/OCB/PKM_...                                \n",
       "4  E:/BGB_example_files_test_last/images/Delivery...                                \n",
       "5  E:/BGB_example_files_test_last/images/Internal...                                \n",
       "6  E:/BGB_example_files_test_last/images/Rental_A...                                \n",
       "7  E:/BGB_example_files_test_last/images/OCB/PKM_...                                \n",
       "8  E:/BGB_example_files_test_last/images/OCB/PKM_...                                \n",
       "9  E:/BGB_example_files_test_last/images/Refunds/...                                "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('E:/BGB_example_files_test_last/labels/all.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRijHJEuy4VC"
   },
   "source": [
    "**Utility Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-j_mJqunXwH"
   },
   "outputs": [],
   "source": [
    "def create_regional_data(path,data_type='train'):\n",
    "  \"\"\"\n",
    "  data_type = train/test/val\n",
    "\n",
    "  \"\"\"\n",
    "  train_dir=path\n",
    "  for folder in tqdm(os.listdir(train_dir)):\n",
    "      for image in os.listdir(train_dir+'/'+folder):\n",
    "          try:\n",
    "              img = cv2.imread(train_dir+'/'+folder+'/'+image,0)\n",
    "              height = img.shape[0]\n",
    "              width = img.shape[1]\n",
    "              header = img[0:(int(height*0.33)), 0:width]\n",
    "              footer = img[int(height*0.67):height, 0:width]\n",
    "              left_body = img[int(height*0.33):int(height*0.67), 0:int(width*0.5)]\n",
    "              right_body = img[int(height*0.33):int(height*0.67), int(width*0.5):width]\n",
    "\n",
    "              header_path=data_type+'/header/'+folder+'/'+image.split('/')[-1]\n",
    "              footer_path=data_type+'/footer/'+folder+'/'+image.split('/')[-1]\n",
    "              left_path=data_type+'/left_body/'+folder+'/'+image.split('/')[-1]\n",
    "              right_path=data_type+'/right_body/'+folder+'/'+image.split('/')[-1]\n",
    "              if(os.path.exists(header_path)==False):\n",
    "                  cv2.imwrite(header_path, header)\n",
    "              if(os.path.exists(footer_path)==False):\n",
    "                  cv2.imwrite(footer_path, footer)\n",
    "              if(os.path.exists(left_path)==False):\n",
    "                  cv2.imwrite(left_path, left_body)\n",
    "              if(os.path.exists(right_path)==False):\n",
    "                  cv2.imwrite(right_path, right_body)\n",
    "          except:\n",
    "            print('Some Error Occured with:',train_dir+'/'+folder+'/'+image)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AugMlQCVnwGE"
   },
   "outputs": [],
   "source": [
    "def get_data_generator(train_dir,test_dir,img_height, img_width,batch_size):\n",
    "    \"\"\"\n",
    "    method to generate training batches on the go, along with data augmentation\n",
    "    \"\"\"\n",
    "    # Using Data Augmentation for better variance\n",
    "    train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=13,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size, \n",
    "    class_mode = \"categorical\")\n",
    "\n",
    "    val_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=13,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2)\n",
    "\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size, \n",
    "    class_mode = \"categorical\")\n",
    "    return train_generator,val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JuotlOU_qxnh"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_y, predict_y,classes):\n",
    "     \n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \"\"\"\n",
    "    This function will plot the consusion matrix.\n",
    "    \"\"\"\n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "   \n",
    "    B =(C/C.sum(axis=0))\n",
    "    labels = classes\n",
    "    cmap=sns.light_palette(\"green\")\n",
    "    # representing A in heatmap format\n",
    "    print(\"-\"*50, \"Confusion matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(17,5))\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\"0.0f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-\"*50, \"Precision matrix\", \"-\"*50)\n",
    "    plt.figure(figsize=(17,5))\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\"0.2f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of columns in precision matrix\",B.sum(axis=0))\n",
    "   \n",
    "    # representing B in heatmap format\n",
    "    print(\"-\"*50, \"Recall matrix\"    , \"-\"*50)\n",
    "    plt.figure(figsize=(17,5))\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\"0.2f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.show()\n",
    "    print(\"Sum of rows in precision matrix\",A.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lS9Y7Ox0q4YK"
   },
   "outputs": [],
   "source": [
    "def eval_model(model,test_generator,limit):\n",
    "    \"\"\"\n",
    "   This function predicts the result of a candidate model\n",
    "   test_generator : genertaor to evaluate\n",
    "   model : candidate model\n",
    "   limit: No of test samples to consider\n",
    "    \n",
    "    \"\"\"\n",
    "    x,y=test_generator.next()\n",
    "    y_pred=[]\n",
    "    y_true=[]\n",
    "    count=0\n",
    "    for i in range(len(x)):\n",
    "        pred=model.predict(np.expand_dims(x[i], axis=0))\n",
    "        predicted_y=np.argmax(pred)\n",
    "        y_pred.append(predicted_y)\n",
    "        y_true.append(np.argmax(y[i]))\n",
    "        count+=1\n",
    "        # limit the number of samples to be considered\n",
    "        if(count==limit):\n",
    "            break\n",
    "    return y_pred,y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CTbYdl6Sq88K"
   },
   "outputs": [],
   "source": [
    "def get_f1_precision_recall(y_pred,y_true):\n",
    "    \"\"\"\n",
    "    This function evaluate the performance(accuracy,f1-score,precision,recall,confusion matrix of the network).\n",
    "    \"\"\"\n",
    "    f1=np.round(f1_score(y_pred,y_true,average='macro'),3)\n",
    "    precision=np.round(precision_score(y_pred,y_true,average='macro'),3)\n",
    "    recall=np.round(recall_score(y_pred,y_true,average='macro'),3)\n",
    "    return f1,precision,recall   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUh2C_REq_cN"
   },
   "outputs": [],
   "source": [
    "def get_result(model,test_generator):\n",
    "    res_test=model.evaluate_generator(test_generator)\n",
    "    print('Test Accuracy:',res_test[1]*100,'%')\n",
    "    y_pred,y_true=eval_model(model,test_generator,2000)\n",
    "    f1,precision,recall=get_f1_precision_recall(y_pred,y_true)\n",
    "    print('Macro F1 Score:',f1)\n",
    "    print('Precision Score:',precision)\n",
    "    print('Recall Score:',recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "maLn_at9wn6W"
   },
   "outputs": [],
   "source": [
    "# Method to check if all the classes are present in test data\n",
    "def sanity_check(y_val):\n",
    "  labels=[]\n",
    "  for i in range(len(y_val)):\n",
    "      labels.append(np.argmax(y_val[i]))\n",
    "  print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDW43Dn-wvxP"
   },
   "outputs": [],
   "source": [
    "# Internal method to calculate performance metrics\n",
    "def get_result_(y_pred,y_true,classes):\n",
    "    print('-----Model Evaluation------')\n",
    "    accuracy=np.round(accuracy_score(y_pred,y_true),2)\n",
    "    print('Accuracy Score:',accuracy)\n",
    "    f1,precision,recall=get_f1_precision_recall(y_pred,y_true)\n",
    "    print('Macro F1 Score:',f1)\n",
    "    print('Precision Score:',precision)\n",
    "    print('Recall Score:',recall)\n",
    "    plot_confusion_matrix(y_true,y_pred,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9Nq3cXawihR"
   },
   "outputs": [],
   "source": [
    "# Method to generate test data for final model evaluation\n",
    "# Note: we are not shuffeling the data here as we need to take the wholistic and regional data for an image in sequence\n",
    "def generate_test_data(val_path,num_samples,img_height, img_width):\n",
    "    \"\"\" This method will generate data to generate features for meta classifier\"\"\"\n",
    "    datagen = ImageDataGenerator(rescale = 1./255,featurewise_center=True,\n",
    "    featurewise_std_normalization=True,rotation_range=13,width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2)\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "    val_path,target_size = (img_height, img_width),batch_size =num_samples , class_mode = \"categorical\",shuffle=False)\n",
    "    x_val,y_val=val_generator.next()\n",
    "    return x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZUil108wqAV"
   },
   "outputs": [],
   "source": [
    "# Method to evaluate final model\n",
    "def eval_stacked_model(weights,x_val,x_val_top,x_val_bottom,x_val_left,x_val_right,y_val\n",
    "    ,model_final_holistic,model_final_top,model_final_bottom,model_final_left,model_final_right,classes,matrix=False):\n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "    for i in range(len(x_val)):\n",
    "        pred_whole=model_final_holistic.predict(np.expand_dims(x_val[i], axis=0))\n",
    "        pred_top=model_final_top.predict(np.expand_dims(x_val_top[i], axis=0))\n",
    "        pred_bottom=model_final_bottom.predict(np.expand_dims(x_val_bottom[i], axis=0))\n",
    "        pred_left=model_final_left.predict(np.expand_dims(x_val_left[i], axis=0))\n",
    "        pred_right= model_final_right.predict(np.expand_dims(x_val_right[i], axis=0))  \n",
    "        try:\n",
    "            # we will concatenate the predictions of the candidate models\n",
    "            predicted_y=np.argmax(pred_whole*weights[0]+pred_top*weights[1]+pred_bottom*weights[2]\n",
    "                               +pred_left*weights[3]+ pred_right*weights[4])\n",
    "            y_pred.append(predicted_y)\n",
    "        except:\n",
    "            print('Some error occured.')\n",
    "            y_pred.append(np.argmax(pred_whole))\n",
    "        y_true.append(np.argmax(y_val[i]))\n",
    "    if(matrix==True):      \n",
    "        get_result_(y_pred,y_true,classes)      \n",
    "    return y_true,y_pred        \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_preprocessing():\n",
    "    train_dir='E:/BGB_example_files_test_last/images'\n",
    "    if(os.path.exists('E:/BGB_example_files_test_last/train')==False):\n",
    "        os.mkdir('E:/BGB_example_files_test_last/train') \n",
    "    if(os.path.exists('E:/BGB_example_files_test_last/test')==False):    \n",
    "        os.mkdir('E:/BGB_example_files_test_last/test')  \n",
    "    if(os.path.exists('E:/BGB_example_files_test_last/val')==False):    \n",
    "        os.mkdir('E:/BGB_example_files_test_last/val')        \n",
    "    regions = ['header', 'footer', 'left_body', 'right_body']\n",
    "    classes=[]\n",
    "    for folders in os.listdir('E:/BGB_example_files_test_last/images'):\n",
    "        classes.append(folders)\n",
    "    # Test directory for wholistic model\n",
    "    test_dir='E:/BGB_example_files_test_last/test/whole'  \n",
    "    val_dir='E:/BGB_example_files_test_last/val/whole'    \n",
    "    if(os.path.exists(test_dir)== False):\n",
    "        os.mkdir(test_dir)\n",
    "    if(os.path.exists(val_dir)== False):\n",
    "        os.mkdir(val_dir)  \n",
    "    for folder in classes:\n",
    "        if(os.path.exists('E:/BGB_example_files_test_last/test/whole'+folder)== False):\n",
    "            os.mkdir('E:/BGB_example_files_test_last/test/whole'+folder)  \n",
    "        if(os.path.exists('E:/BGB_example_files_test_last/val/whole'+folder)== False):\n",
    "            os.mkdir('E:/BGB_example_files_test_last/val/whole'+folder)   \n",
    "    \n",
    "    # Moving files from source to test and  directory\n",
    "    source_dir='E:/BGB_example_files_test_last/images'    \n",
    "    dest_dir='E:/BGB_example_files_test_last/test/whole'             \n",
    "    # Configure test and val data percentage here\n",
    "    # we are going with train 0.8, test 0.1, val 0.1\n",
    "    test_percentage=0.1\n",
    "    val_percentage=0.1\n",
    "    for folder in os.listdir(source_dir):\n",
    "        files=os.listdir(source_dir+'/'+folder)\n",
    "        count=0\n",
    "        num_image_per_class=math.ceil(len(files)*test_percentage)\n",
    "        shuffle(files)\n",
    "        for file in files:\n",
    "            if(count!=num_image_per_class):\n",
    "                source=source_dir+'/'+folder+'/'+file\n",
    "                dest=dest_dir+'/'+folder+'/'+file\n",
    "                if(os.path.exists(dest)==False):\n",
    "                    shutil.move(source,dest)\n",
    "                    count+=1\n",
    "    dest_dir='E:/BGB_example_files_test_last/val/whole'           \n",
    "    for folder in os.listdir(source_dir):\n",
    "        files=os.listdir(source_dir+'/'+folder)\n",
    "        count=0\n",
    "        num_image_per_class=math.ceil(len(files)*val_percentage)\n",
    "        shuffle(files)\n",
    "        for file in files:\n",
    "            if(count!=num_image_per_class):\n",
    "                source=source_dir+'/'+folder+'/'+file\n",
    "                dest=dest_dir+'/'+folder+'/'+file\n",
    "                if(os.path.exists(dest)==False):\n",
    "                    shutil.move(source,dest)\n",
    "                    count+=1 \n",
    "    # Create folder structure for regional data\n",
    "    for region in regions:\n",
    "        if(os.path.exists('E:/BGB_example_files_test_last/train/'+region)==False):\n",
    "            os.mkdir('E:/BGB_example_files_test_last/train/'+region)\n",
    "        if(os.path.exists('E:/BGB_example_files_test_last/test/'+region)==False):\n",
    "            os.mkdir('E:/BGB_example_files_test_last/test/'+region)\n",
    "        if(os.path.exists('E:/BGB_example_files_test_last/val/'+region)==False):\n",
    "            os.mkdir('E:/BGB_example_files_test_last/val/'+region)    \n",
    "    for region in regions:\n",
    "        for folder in classes:\n",
    "            if(os.path.exists('E:/BGB_example_files_test_last/test/'+region+'/'+folder)== False):\n",
    "                os.mkdir('E:/BGB_example_files_test_last/test/'+region+'/'+folder) \n",
    "            if(os.path.exists('E:/BGB_example_files_test_last/train/'+region+'/'+folder)== False):\n",
    "                os.mkdir('E:/BGB_example_files_test_last/train/'+region+'/'+folder)\n",
    "            if(os.path.exists('E:/BGB_example_files_test_last/val/'+region+'/'+folder)== False):\n",
    "                os.mkdir('E:/BGB_example_files_test_last/val/'+region+'/'+folder)  \n",
    "    if(os.path.exists('E:/BGB_example_files_test_last/train/whole')==False):            \n",
    "        os.mkdir('E:/BGB_example_files_test_last/train/whole')        \n",
    "    source_dir='E:/BGB_example_files_test_last/val/whole'                 \n",
    "    create_regional_data(source_dir,data_type='val') \n",
    "    source_dir='E:/BGB_example_files_test_last/train/whole'          \n",
    "    create_regional_data(source_dir,data_type='train')    \n",
    "    source_dir='E:/BGB_example_files_test_last/test/whole'      \n",
    "    create_regional_data(source_dir,data_type='test') \n",
    "    print('[Info] Preprocessing Completed')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONFIGURE MODEL LEVEL GRIDSEARCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab_type": "text",
    "id": "zEGGGDA_y_PP"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters to tune\n",
    "epochs_ = [5]\n",
    "optimizer = ['SGD','Adam']\n",
    "batch_sizes=[32,20]\n",
    "learn_rate = [0.0001, 0.001]\n",
    "#param_grid = dict(learn_rate=learn_rate,batch_size=batch_sizes,epochs=epochs_ )\n",
    "param_grid = dict(learn_rate=learn_rate,batch_size=batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    def create_model(learn_rate=0.0001,optimizer='adam'):\n",
    "        model =keras.applications.vgg16.VGG16(weights = None, include_top=False, input_shape = (img_width, img_height, 3))   \n",
    "        for layer in model.layers:\n",
    "            layer.trainable=True\n",
    "        #Adding custom Layers \n",
    "        x = model.output\n",
    "        x = Flatten()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(256, activation=\"relu\")(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        predictions = Dense(27, activation=\"softmax\")(x)\n",
    "        # creating the final model \n",
    "        model_ = Model( model.input,  predictions)\n",
    "        # compile the model \n",
    "        optimizer=keras.optimizers.Adam(lr=learn_rate) #<--Comment out this line if optimizer is  tuned\n",
    "        model_.compile(loss = \"categorical_crossentropy\", optimizer =optimizer, metrics=[\"accuracy\"])  \n",
    "        return model_\n",
    "\n",
    "    def create_regional_model(learn_rate=0.0001,optimizer='adam'):\n",
    "        model= create_model(learn_rate=0.0001,optimizer='adam')   \n",
    "        model.load_weights('whole.hdf5')\n",
    "        return model      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(data_generator,model_type):\n",
    "    x,y=data_generator.next()\n",
    "    if(model_type=='whole'):\n",
    "        build_fn=create_model\n",
    "    else:\n",
    "        build_fn=create_regional_model    \n",
    "    model = KerasClassifier(build_fn, verbose=1)\n",
    "    grid_search = GridSearchCV(model, param_grid)\n",
    "    print('[Info] GridSearch Started')\n",
    "    grid_result=grid_search.fit(x,y)\n",
    "    best_batch=grid_result.best_params_['batch_size']\n",
    "    best_epoch=grid_result.best_params_['epochs'] \n",
    "    print('Best params:'+str(grid_result.best_params_))\n",
    "    print('[Info] GridSearch Completed')\n",
    "    return best_batch, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_models(whole_train_path='E:/BGB_example_files_test_last/images',whole_test_path='E:/BGB_example_files_test_last/val/whole' \n",
    "                          ,model_type='whole',batch_size=50,name='whole',epochs=20,enable_gridSearch=True):\n",
    "    train_generator,val_generator=get_data_generator(whole_train_path,whole_test_path,img_height, img_width,500)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001)\n",
    "    mcp_save = ModelCheckpoint(name+'.hdf5', save_best_only=True, monitor='acc', mode='max')\n",
    "    if(model_type=='whole'):\n",
    "        model=create_model()  \n",
    "    else:\n",
    "        model=create_regional_model()    \n",
    "    print('[Info] Model Created -'+name)          \n",
    "    # Wholistic Model\n",
    "    print('[Info] Model Training Started -'+name)\n",
    "    # Hyperparameter Configuration -- SET BEST HYPERPARAMETER OBTAINED\n",
    "    if(enable_gridSearch==True):\n",
    "          # RETURN the hyperparameters used in perform_grid_search\n",
    "          best_batch,best_epoch=perform_grid_search(val_generator,model_type)\n",
    "          perform_grid_search(val_generator,model_type)\n",
    "          batch_size=best_batch\n",
    "          epochs=best_epoch\n",
    "          print('[Info] Train Started using best hyperparameter settings')      \n",
    "    history=model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,steps_per_epoch = 5000/batch_size,    \n",
    "    validation_data=val_generator,\n",
    "    validation_steps=math.ceil(500//(batch_size)),\n",
    "    callbacks=[reduce_lr,mcp_save])\n",
    "    model.save(name+'.hdf5')   \n",
    "    # Eval model on test data\n",
    "    get_result(model,val_generator)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configurations\n",
    "img_width=256\n",
    "img_height=256\n",
    "batch_size=10\n",
    "epochs = 10\n",
    "num_classes=27\n",
    "whole_train_path='E:/BGB_example_files_test_last/images'\n",
    "whole_test_path='E:/BGB_example_files_test_last/val/whole' \n",
    "footer_train_path='E:/BGB_example_files_test_last/train/footer'   \n",
    "footer_test_path='E:/BGB_example_files_test_last/val/footer'\n",
    "header_train_path='E:/BGB_example_files_test_last/train/header'       \n",
    "header_test_path='E:/BGB_example_files_test_last/val/header' \n",
    "left_train_path='E:/BGB_example_files_test_last/train/left_body'\n",
    "left_test_path='E:/BGB_example_files_test_last/val/left_body' \n",
    "right_train_path='E:/BGB_example_files_test_last/train/right_body'  \n",
    "right_test_path='E:/BGB_example_files_test_last/val/right_body'     \n",
    "classes=[]\n",
    "for folders in os.listdir(whole_train_path):\n",
    "    classes.append(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:/BGB_example_files_test_last/test/whole/Collection_Note/SKM_C364e19052113410-16.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\vgg\\lib\\shutil.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    565\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Den angivne sti blev ikke fundet: 'E:/BGB_example_files_test_last/images/Collection_Note/SKM_C364e19052113410-16.png' -> 'E:/BGB_example_files_test_last/test/whole/Collection_Note/SKM_C364e19052113410-16.png'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-10605bfd9083>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mperform_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-93-ef89040a9230>\u001b[0m in \u001b[0;36mperform_preprocessing\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mdest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdest_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                     \u001b[0mcount\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mdest_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'E:/BGB_example_files_test_last/val/whole'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\vgg\\lib\\shutil.py\u001b[0m in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m             \u001b[0mcopy_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\vgg\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\vgg\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/BGB_example_files_test_last/test/whole/Collection_Note/SKM_C364e19052113410-16.png'"
     ]
    }
   ],
   "source": [
    "perform_preprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute GridSearch on Single Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3686 images belonging to 27 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parameter grid for parameter (batch_size) needs to be a list or numpy array, but got (<class 'int'>). Single values need to be wrapped in a list with one element.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-d0e1e38064d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_data_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhole_train_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwhole_test_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mperform_grid_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'whole'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-e7f474bbeecc>\u001b[0m in \u001b[0;36mperform_grid_search\u001b[1;34m(data_generator, model_type)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_regional_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[Info] GridSearch Started'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mgrid_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\vgg\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\vgg\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, estimator, param_grid, scoring, n_jobs, iid, refit, cv, verbose, pre_dispatch, error_score, return_train_score)\u001b[0m\n\u001b[0;32m   1182\u001b[0m             return_train_score=return_train_score)\n\u001b[0;32m   1183\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m         \u001b[0m_check_param_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\vgg\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_check_param_grid\u001b[1;34m(param_grid)\u001b[0m\n\u001b[0;32m    391\u001b[0m                                  \u001b[1;34m\" be a list or numpy array, but got ({1}).\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                                  \u001b[1;34m\" Single values need to be wrapped in a list\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m                                  \" with one element.\".format(name, type(v)))\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Parameter grid for parameter (batch_size) needs to be a list or numpy array, but got (<class 'int'>). Single values need to be wrapped in a list with one element."
     ]
    }
   ],
   "source": [
    "param_grid = dict(learn_rate=learn_rate,batch_size=batch_size)\n",
    "train_generator,val_generator=get_data_generator(whole_train_path,whole_test_path,img_height, img_width,batch_size=200)\n",
    "perform_grid_search(val_generator,model_type='whole')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anchor Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(img_width=256,img_height=256,batch_size=32,epochs = 10,num_classes=27,\n",
    "          samples_per_epoch =5000,skip_train=False,enable_gridSearch=False,tune_stack=False,stack_weights=None):\n",
    "    \"\"\"\n",
    "    img_width: width of images,256\n",
    "    img_height: height of images, 256\n",
    "    batch_size: size of trainning batch, 32\n",
    "    epochs: number of epochs, 30\n",
    "    num_classes: No of unique labels, 27\n",
    "    samples_per_epoch: samples for training in each epoch, 1000\n",
    "    skip_train: flag to skip training if trained models are already present, False\n",
    "    \"\"\"\n",
    "    print('[Info] Pipeline Processing Started')\n",
    "    # Skip this line if already preprocessed\n",
    "    perform_preprocessing()\n",
    "    if(skip_train==False):\n",
    "        model_final_holistic=get_individual_models(whole_train_path,whole_test_path,model_type='whole',\n",
    "                                              batch_size=batch_size,name='whole',epochs=epochs,enable_gridSearch=False)\n",
    "        model_final_top=get_individual_models(header_train_path,header_test_path,model_type='reg',\n",
    "                                              batch_size=batch_size,name='header',epochs=epochs,enable_gridSearch=False)\n",
    "        model_final_bottom=get_individual_models(footer_train_path,footer_test_path,model_type='reg',\n",
    "                                              batch_size=batch_size,name='footer',epochs=epochs,enable_gridSearch=False)\n",
    "        model_final_left=get_individual_models(left_train_path,left_test_path,model_type='reg',\n",
    "                                              batch_size=batch_size,name='left',epochs=epochs,enable_gridSearch=True)\n",
    "        model_final_right= get_individual_models(right_train_path,right_test_path,model_type='reg',\n",
    "                                              batch_size=batch_size,name='right',epochs=epochs,enable_gridSearch=False)\n",
    "    else:\n",
    "        model=create_model()\n",
    "        model_final_holistic=model.load_weights('whole.hdf5')\n",
    "        model_final_top=model.load_weights('header.hdf5')\n",
    "        model_final_bottom=model.load_weights('footer.hdf5')\n",
    "        model_final_left=model.load_weights('left.hdf5')\n",
    "        model_final_right=model.load_weights('right.hdf5')\n",
    "        model_final_left=get_individual_models(left_train_path,left_test_path,model_type='reg',\n",
    "                                              batch_size=batch_size,name='left',epochs=epochs,enable_gridSearch=True)        \n",
    "    x_val,y_val=generate_test_data('E:/BGB_example_files_test_last/test/whole',500,img_height, img_width)              #change\n",
    "    x_val_top,y_val_top=generate_test_data('E:/BGB_example_files_test_last/test/header',500,img_height, img_width)     #change\n",
    "    x_val_bottom,y_val_bottom=generate_test_data('E:/BGB_example_files_test_last/test/footer',500,img_height, img_width) #chnge\n",
    "    x_val_left,y_val_left=generate_test_data('E:/BGB_example_files_test_last/test/left_body',500,img_height, img_width)  #Change\n",
    "    x_val_right,y_val_right=generate_test_data('E:/BGB_example_files_test_last/test/right_body',500,img_height, img_width) #change\n",
    "    # Default Weights\n",
    "    weights=[0.4,0.2,0.2,0.1,0.1]\n",
    "    if(tune_stack==True):\n",
    "        stack_accuracy=[]  \n",
    "        for weights in stack_weights:\n",
    "            y_true,y_pred=eval_stacked_model(weights,x_val,x_val_top,x_val_bottom,x_val_left,x_val_right,y_val,\n",
    "            model_final_holistic,model_final_top,model_final_bottom,model_final_left,model_final_right,classes)\n",
    "            accuracy=np.round(accuracy_score(y_pred,y_true),2)\n",
    "            print('---------------------')\n",
    "            print('Weight:',str(weights))\n",
    "            print('Accuracy:',accuracy)\n",
    "            print('---------------------')\n",
    "            stack_accuracy.append(accuracy)\n",
    "        weights= stack_weights[np.argmax(stack_accuracy)] \n",
    "        print('Best Weights:',str(weights))       \n",
    "    y_true,y_pred=eval_stacked_model(weights,x_val,x_val_top,x_val_bottom,x_val_left,x_val_right,y_val,\n",
    "    model_final_holistic,model_final_top,model_final_bottom,model_final_left,model_final_right,classes,matrix=True)\n",
    "    print('[Info] Model Eval Completed.')\n",
    "    print(classification_report(y_true,y_pred))\n",
    "    print('[Info]True Label vs Prediction Eval')\n",
    "    index=[]\n",
    "    for i in range(20):\n",
    "        index.append(randint(0,len(y_pred)))\n",
    "    for i in index:\n",
    "        print('True Class:'+str(y_true[i])+' Predicted Class:'+str(y_pred[i]))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Script_BGB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
